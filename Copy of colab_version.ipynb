{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of colab_version.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1bhGrwI1u460NBbfTiRR37u1TOh74F3Lw","authorship_tag":"ABX9TyOGUB/FEE2AvDMTYWE2Vmbn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-a4XaMf--rrw","colab_type":"code","outputId":"e3fa3943-eab7-4f51-dc67-cd0e0badda86","executionInfo":{"status":"ok","timestamp":1589038366054,"user_tz":-120,"elapsed":5779,"user":{"displayName":"Juan Álvarez","photoUrl":"","userId":"06378331534551784227"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","import gym\n","import cv2\n","import argparse\n","import sys, glob\n","import numpy as np\n","import pandas as pd\n","import pdb\n","import keras\n","from keras import backend as K\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Input, Dense, Reshape\n","from keras.layers.wrappers import TimeDistributed\n","from keras.optimizers import Adam, Adamax, RMSprop\n","from keras.layers.advanced_activations import PReLU\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.core import Activation, Dropout, Flatten\n","from keras.layers.convolutional import UpSampling2D, Convolution2D\n","IMAGE_LENGTH = int(33600)\n","epochs = 10\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oieGtLiX-vUM","colab_type":"code","colab":{}},"source":["def load_data(path):\n","    #pdb.set_trace()\n","    df = pd.read_csv(path, sep = '.', header = None)\n","    letters = df[(df.index % (IMAGE_LENGTH+1)==0)].values.tolist()\n","    images = df[(df.index % (IMAGE_LENGTH+1)!=0)].values.tolist()\n","    n =IMAGE_LENGTH\n","    final = [images[i * n:(i + 1) * n] for i in range((len(images) + n - 1) // n )]  \n","    #pdb.set_trace()\n","    return letters, final"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lE1zpo3e-6Ky","colab_type":"code","colab":{}},"source":["# Prepare first dataset \n","letter, final = load_data('/content/drive/My Drive/DATOS/EIT/NICE ACADEMIC/AI/project/dataset_thomas_v1.txt')\n","for i in range (0, len(final)):\n","    final[i] = np.concatenate(final[i])\n","#pdb.set_trace()\n","\n","letter = np.concatenate(letter)\n","final = np.array(final)\n","letter=letter.reshape(1, len(letter))\n","letter = letter[0, :]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8AFl_qkGDZEY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"67b74a19-1685-48ef-9a4b-595b367f3d12","executionInfo":{"status":"error","timestamp":1589038529306,"user_tz":-120,"elapsed":165860,"user":{"displayName":"Juan Álvarez","photoUrl":"","userId":"06378331534551784227"}}},"source":["# Prepare  second dataset \n","letter2, final2 = load_data('/content/drive/My Drive/DATOS/EIT/NICE ACADEMIC/AI/project/dataset_v2.txt')\n","for i in range (0, len(final2)):\n","    final2[i] = np.concatenate(final2[i])\n","#pdb.set_trace()\n","\n","letter2 = np.concatenate(letter2)\n","final2 = np.array(final2)\n","letter2=letter2.reshape(1, len(letter2))\n","letter2 = letter2[0, :]"],"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-59f3cc13c5f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mletter2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/DATOS/EIT/NICE ACADEMIC/AI/project/dataset_v2.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfinal2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-c9eece967582>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mletters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMAGE_LENGTH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMAGE_LENGTH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/drive/My Drive/DATOS/EIT/NICE ACADEMIC/AI/project/dataset_v2.txt does not exist: '/content/drive/My Drive/DATOS/EIT/NICE ACADEMIC/AI/project/dataset_v2.txt'"]}]},{"cell_type":"code","metadata":{"id":"3_OT1w5HFdmG","colab_type":"code","colab":{}},"source":["# Prepare third dataset\n","# Prepare  second dataset \n","letter3, final3 = load_data('/content/drive/My Drive/DATOS/EIT/NICE ACADEMIC/AI/project/dataset_thomas_v3.txt')\n","for i in range (0, len(final3)):\n","    final3[i] = np.concatenate(final3[i])\n","#pdb.set_trace()\n","\n","letter3 = np.concatenate(letter3)\n","final3 = np.array(final3)\n","letter3=letter3.reshape(1, len(letter3))\n","letter3 = letter3[0, :]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nz1X1W8OAHc","colab_type":"code","colab":{}},"source":["# Prepare third dataset\n","# Prepare  second dataset \n","letter4, final4 = load_data('/content/drive/My Drive/DATOS/EIT/NICE ACADEMIC/AI/project/dataset_haider_v1.txt')\n","for i in range (0, len(final4)):\n","    final4[i] = np.concatenate(final4[i])\n","#pdb.set_trace()\n","\n","letter4 = np.concatenate(letter4)\n","final4 = np.array(final4)\n","letter4=letter4.reshape(1, len(letter4))\n","letter4 = letter4[0, :]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eg2lgyvJEdu7","colab_type":"code","colab":{}},"source":["final = np.concatenate((final, final2, final3, final4))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_TLZS1JvE7bs","colab_type":"code","colab":{}},"source":["letter = np.concatenate((letter, letter2, letter3, letter4))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9gxAZo5FFru","colab_type":"code","colab":{}},"source":["final.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cSMMhGGEEpt","colab_type":"code","colab":{}},"source":["# Split dataset using a rule of 0.7\n","train_ratio = 0.7\n","\n","n_train_samples = int(len(final) * train_ratio)\n","x_train, y_train = final[:n_train_samples], letter[:n_train_samples]\n","x_val, y_val = final[n_train_samples:], letter[n_train_samples:]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EqTqHUX6GvBt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vPf0vS9I-8sc","colab_type":"code","colab":{}},"source":["num_classes = 9\n","#x_train /= 255\n","#x_val /= 255\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_val = keras.utils.to_categorical(y_val, num_classes)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6w5FwMQCDDsn","colab_type":"code","colab":{}},"source":["# Input shape will be determined by x_train\n","model = Sequential()\n","model.add(Dense(150, activation='sigmoid', input_shape=(33600,)))\n","model.add(Dense(200, activation='sigmoid'))\n","model.add(Dense(240, activation='sigmoid'))\n","model.add(Dense(400, activation='sigmoid'))\n","model.add(Dense(333, activation='sigmoid'))\n","model.add(Dense(231, activation='sigmoid'))\n","model.add(Dense(147, activation='sigmoid'))\n","model.add(Dense(100, activation='sigmoid'))\n","model.add(Dense(50, activation='sigmoid'))\n","model.add(Dense(40, activation='sigmoid'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='nadam',\n","              metrics=['accuracy'])\n","#pdb.set_trace()\n","history = model.fit(x_train, y_train,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_val, y_val))\n","score = model.evaluate(x_val, y_val, verbose=0)\n","print('Validation loss:', score[0])\n","print('Validation accuracy:', score[1])\n","# This code saves the weights\n","model_json = model.to_json()\n","with open(\"model.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","model.save_weights(\"model_weights.h5\")\n","print(\"Saved model to disk\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4Uf6RL4DVh7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}